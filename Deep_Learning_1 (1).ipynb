{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY2-NcZaECPV"
   },
   "source": [
    "# Model -  Sequential\n",
    "\n",
    "**Sequential is the easiest way to build a model in Keras. It allows you to build a model layer by layer. Each layer has weights that correspond to the layer the follows it.**\n",
    "\n",
    "\n",
    "* We use the **‘add()’**  function to add layers to our model.\n",
    "\n",
    "\n",
    "* **‘Dense’** is the layer type. Dense is a standard layer type that works for most cases. In a dense layer, all nodes in the previous layer connect to the nodes in the current layer.\n",
    "\n",
    "\n",
    "**We define nodes in each of our input layers. This number can also be in the hundreds or thousands. Increasing the number of nodes in each layer increases model capacity. I will go into further detail about the effects of increasing model capacity shortly.**\n",
    "\n",
    "\n",
    "* **‘Activation’** is the activation function for the layer. An activation function allows models to take into account nonlinear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRevaPp6ECPX"
   },
   "source": [
    "**The first layer needs an input shape. The input shape specifies the number of rows and columns in the input.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTQbiteOECPY"
   },
   "source": [
    "**The last layer is the output layer. It only has one node, two nodes as per requirment. which is for our prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83ZTm03EECPZ"
   },
   "source": [
    "# Compiling Model. \n",
    "\n",
    "**Compiling the model takes two parameters: optimizer and loss.**\n",
    "\n",
    "* The **optimizer** controls the learning rate. We will be using **‘adam’** as our optmizer. \n",
    "\n",
    "* Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n",
    "\n",
    "* The learning rate determines how fast the optimal weights for the model are calculated. A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
    "\n",
    "* For our loss function, we will use ‘as per requirment ( regression or Classification’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAOm-0lsECPa"
   },
   "source": [
    "# Train\n",
    "\n",
    "* we will use the ‘fit()’ function on our model with the following five parameters: \n",
    "* training data (train_X), \n",
    "* target data (train_y), \n",
    "* validation split, \n",
    "* number of epochs \n",
    "* callbacks.\n",
    "\n",
    "* The validation split will randomly split the data into use for training and testing. \n",
    "\n",
    "* During training, we will be able to see the validation loss, If we will set the validation split at 0.2, which means that 20% of the training data we provide in the model will be set aside for testing model performance.\n",
    "\n",
    "* The number of epochs is the number of times the model will cycle through the data. The more epochs we run, the more the model will improve, up to a certain point. After that point, the model will stop improving during each epoch. In addition, the more epochs, the longer the model will take to run. To monitor this, we will use ‘early stopping’.\n",
    "\n",
    "* Early stopping will stop the model from training before the number of epochs is reached if the model stops improving. We will set our early stopping monitor to 3. This means that after 3 epochs in a row in which the model doesn’t improve, training will stop. Sometimes, the validation loss can stop improving then improve in the next epoch, but after 3 epochs in which the validation loss doesn’t improve, it usually won’t improve again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkTXN3SkECPb"
   },
   "source": [
    "* to make predictions on new data, we would use the *‘predict()’* function, passing in our new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9M2hRzxECPc"
   },
   "source": [
    "**As you increase the number of nodes and layers in a model, the model capacity increases. Increasing model capacity can lead to a more accurate model, up to a certain point, at which the model will stop improving. Generally, the more training data you provide, the larger the model should be.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9pgXM8wECPc"
   },
   "source": [
    "#  Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow  ,in anaconda prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install keras  , in anaconda prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99293I--mwjt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2537BMEcnAHU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential    #  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTeJJ5TpnAWJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "speqEhqPn5Vb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oRtmuChnAm-"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/shyam/Documents/datasets/IRIS.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Y6_rZHcYotks",
    "outputId": "4c2400dd-aee2-41ce-f689-78ab5879f238"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "X_Z6bn2lpXsR",
    "outputId": "82c558c2-9201-4eb7-c86e-920542489126"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "species          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xxi3wIcqpXvV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOfP7EX2tCcY"
   },
   "outputs": [],
   "source": [
    "data['species'] = lc.fit_transform(data['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "HhFh4-wIpXwv",
    "outputId": "6e287b19-4677-4f3e-c8a0-73057f706479"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "jx6WhAMkpXzf",
    "outputId": "28c94661-1477-4fc5-b929-43027e0ccbd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eNAPEH1pX0x"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "RnrNWRpTpX4v",
    "outputId": "e22ce3f2-a72d-4526-83a0-c32dd214ea5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()   # Independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['species']   # dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9lWotpXpYEi"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))# if 2 categorical output , sigmoid activation\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6VM4X5LBpX_P",
    "outputId": "6daaa873-1280-47e1-bd9b-de23b8540512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 1.2450 - accuracy: 0.3333 - val_loss: 1.1586 - val_accuracy: 0.4167\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1507 - accuracy: 0.3438 - val_loss: 1.0769 - val_accuracy: 0.6250\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0569 - accuracy: 0.5625 - val_loss: 0.9973 - val_accuracy: 0.4167\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9864 - accuracy: 0.3438 - val_loss: 0.9677 - val_accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9638 - accuracy: 0.4271 - val_loss: 0.9434 - val_accuracy: 0.6667\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9317 - accuracy: 0.5938 - val_loss: 0.9132 - val_accuracy: 0.7083\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9051 - accuracy: 0.6667 - val_loss: 0.8924 - val_accuracy: 0.7500\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8831 - accuracy: 0.7708 - val_loss: 0.8693 - val_accuracy: 0.8750\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8614 - accuracy: 0.7604 - val_loss: 0.8477 - val_accuracy: 0.8333\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8443 - accuracy: 0.7292 - val_loss: 0.8289 - val_accuracy: 0.8333\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.8438 - val_loss: 0.8115 - val_accuracy: 0.8750\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8079 - accuracy: 0.8438 - val_loss: 0.7944 - val_accuracy: 0.8750\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7887 - accuracy: 0.8438 - val_loss: 0.7812 - val_accuracy: 0.8750\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7734 - accuracy: 0.8646 - val_loss: 0.7665 - val_accuracy: 0.8750\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.8438 - val_loss: 0.7526 - val_accuracy: 0.8750\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.8646 - val_loss: 0.7401 - val_accuracy: 0.9167\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7285 - accuracy: 0.8854 - val_loss: 0.7235 - val_accuracy: 0.9167\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7166 - accuracy: 0.8646 - val_loss: 0.7082 - val_accuracy: 0.9167\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6999 - accuracy: 0.8646 - val_loss: 0.6948 - val_accuracy: 0.9167\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.9062 - val_loss: 0.6813 - val_accuracy: 0.9167\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.9271 - val_loss: 0.6686 - val_accuracy: 0.9583\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.9271 - val_loss: 0.6520 - val_accuracy: 0.9167\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.8958 - val_loss: 0.6373 - val_accuracy: 0.9167\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.9167 - val_loss: 0.6243 - val_accuracy: 0.9583\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6156 - accuracy: 0.9375 - val_loss: 0.6084 - val_accuracy: 0.9167\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.9375 - val_loss: 0.5950 - val_accuracy: 0.9583\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.9479 - val_loss: 0.5795 - val_accuracy: 0.9583\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5735 - accuracy: 0.9271 - val_loss: 0.5642 - val_accuracy: 0.9583\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.9271 - val_loss: 0.5502 - val_accuracy: 0.9583\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.9583 - val_loss: 0.5372 - val_accuracy: 0.9583\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.9688 - val_loss: 0.5242 - val_accuracy: 0.9583\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.9688 - val_loss: 0.5078 - val_accuracy: 0.9583\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.9688 - val_loss: 0.4928 - val_accuracy: 0.9583\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.9688 - val_loss: 0.4794 - val_accuracy: 0.9583\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.9688 - val_loss: 0.4659 - val_accuracy: 0.9583\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.9688 - val_loss: 0.4533 - val_accuracy: 0.9583\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.9688 - val_loss: 0.4393 - val_accuracy: 0.9583\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.9688 - val_loss: 0.4274 - val_accuracy: 0.9583\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.9792 - val_loss: 0.4142 - val_accuracy: 0.9583\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.9792 - val_loss: 0.4032 - val_accuracy: 0.9583\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.9792 - val_loss: 0.3915 - val_accuracy: 0.9583\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.9792 - val_loss: 0.3776 - val_accuracy: 0.9583\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.9792 - val_loss: 0.3671 - val_accuracy: 0.9583\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.9792 - val_loss: 0.3569 - val_accuracy: 0.9583\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.9792 - val_loss: 0.3452 - val_accuracy: 0.9583\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.9792 - val_loss: 0.3358 - val_accuracy: 0.9583\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.9792 - val_loss: 0.3251 - val_accuracy: 0.9583\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.9688 - val_loss: 0.3169 - val_accuracy: 0.9583\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.9688 - val_loss: 0.3100 - val_accuracy: 0.9583\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3160 - accuracy: 0.9792 - val_loss: 0.2983 - val_accuracy: 0.9583\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.9688 - val_loss: 0.2910 - val_accuracy: 0.9583\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.9688 - val_loss: 0.2856 - val_accuracy: 0.9583\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9688 - val_loss: 0.2764 - val_accuracy: 0.9583\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.9688 - val_loss: 0.2687 - val_accuracy: 0.9583\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2778 - accuracy: 0.9792 - val_loss: 0.2619 - val_accuracy: 0.9583\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.9792 - val_loss: 0.2560 - val_accuracy: 0.9583\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.9688 - val_loss: 0.2517 - val_accuracy: 0.9583\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.9688 - val_loss: 0.2453 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.9792 - val_loss: 0.2378 - val_accuracy: 0.9583\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.9688 - val_loss: 0.2352 - val_accuracy: 0.9167\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9688 - val_loss: 0.2277 - val_accuracy: 0.9583\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9688 - val_loss: 0.2233 - val_accuracy: 0.9583\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9688 - val_loss: 0.2183 - val_accuracy: 0.9583\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.9688 - val_loss: 0.2170 - val_accuracy: 0.9583\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9688 - val_loss: 0.2102 - val_accuracy: 0.9583\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9792 - val_loss: 0.2055 - val_accuracy: 0.9583\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9792 - val_loss: 0.2019 - val_accuracy: 0.9583\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9688 - val_loss: 0.2006 - val_accuracy: 0.9583\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9688 - val_loss: 0.1950 - val_accuracy: 0.9583\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9688 - val_loss: 0.1921 - val_accuracy: 0.9167\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1990 - accuracy: 0.9688 - val_loss: 0.1886 - val_accuracy: 0.9583\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9688 - val_loss: 0.1846 - val_accuracy: 0.9583\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9688 - val_loss: 0.1826 - val_accuracy: 0.9167\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1975 - accuracy: 0.9688 - val_loss: 0.1786 - val_accuracy: 0.9583\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9688 - val_loss: 0.1805 - val_accuracy: 0.9583\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1845 - accuracy: 0.9792 - val_loss: 0.1742 - val_accuracy: 0.9167\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1797 - accuracy: 0.9688 - val_loss: 0.1703 - val_accuracy: 0.9583\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9688 - val_loss: 0.1680 - val_accuracy: 0.9583\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1753 - accuracy: 0.9688 - val_loss: 0.1666 - val_accuracy: 0.9167\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9688 - val_loss: 0.1644 - val_accuracy: 0.9167\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9688 - val_loss: 0.1606 - val_accuracy: 0.9583\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9688 - val_loss: 0.1590 - val_accuracy: 0.9583\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9792 - val_loss: 0.1567 - val_accuracy: 0.9583\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9688 - val_loss: 0.1585 - val_accuracy: 0.9583\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1631 - accuracy: 0.9896 - val_loss: 0.1569 - val_accuracy: 0.9583\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9688 - val_loss: 0.1515 - val_accuracy: 0.9583\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9792 - val_loss: 0.1510 - val_accuracy: 0.9583\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9688 - val_loss: 0.1543 - val_accuracy: 0.9583\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.9792 - val_loss: 0.1469 - val_accuracy: 0.9583\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1542 - accuracy: 0.9792 - val_loss: 0.1439 - val_accuracy: 0.9583\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.9688 - val_loss: 0.1454 - val_accuracy: 0.9583\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9688 - val_loss: 0.1408 - val_accuracy: 0.9583\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9688 - val_loss: 0.1397 - val_accuracy: 0.9583\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9688 - val_loss: 0.1392 - val_accuracy: 0.9583\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9688 - val_loss: 0.1371 - val_accuracy: 0.9167\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9688 - val_loss: 0.1349 - val_accuracy: 0.9583\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.9688 - val_loss: 0.1379 - val_accuracy: 0.9583\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9688 - val_loss: 0.1326 - val_accuracy: 0.9167\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9688 - val_loss: 0.1320 - val_accuracy: 0.9167\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9688 - val_loss: 0.1301 - val_accuracy: 0.9583\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9688 - val_loss: 0.1297 - val_accuracy: 0.9167\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9688 - val_loss: 0.1272 - val_accuracy: 0.9583\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9688 - val_loss: 0.1268 - val_accuracy: 0.9167\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1282 - accuracy: 0.9896 - val_loss: 0.1273 - val_accuracy: 0.9583\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9688 - val_loss: 0.1245 - val_accuracy: 0.9167\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9688 - val_loss: 0.1233 - val_accuracy: 0.9583\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.9688 - val_loss: 0.1224 - val_accuracy: 0.9167\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9896 - val_loss: 0.1252 - val_accuracy: 0.9583\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1234 - accuracy: 0.9896 - val_loss: 0.1214 - val_accuracy: 0.9583\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1318 - accuracy: 0.9688 - val_loss: 0.1209 - val_accuracy: 0.9583\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1270 - accuracy: 0.9688 - val_loss: 0.1236 - val_accuracy: 0.9583\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9688 - val_loss: 0.1178 - val_accuracy: 0.9167\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9688 - val_loss: 0.1166 - val_accuracy: 0.9583\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9688 - val_loss: 0.1156 - val_accuracy: 0.9583\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9688 - val_loss: 0.1144 - val_accuracy: 0.9583\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9688 - val_loss: 0.1172 - val_accuracy: 0.9583\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9896 - val_loss: 0.1146 - val_accuracy: 0.9583\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9688 - val_loss: 0.1123 - val_accuracy: 0.9583\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9688 - val_loss: 0.1120 - val_accuracy: 0.9167\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 0.9688 - val_loss: 0.1112 - val_accuracy: 0.9167\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9688 - val_loss: 0.1099 - val_accuracy: 0.9583\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1076 - accuracy: 0.9688 - val_loss: 0.1102 - val_accuracy: 0.9167\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9792 - val_loss: 0.1097 - val_accuracy: 0.9583\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9688 - val_loss: 0.1081 - val_accuracy: 0.9583\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9688 - val_loss: 0.1083 - val_accuracy: 0.9167\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9688 - val_loss: 0.1073 - val_accuracy: 0.9167\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9688 - val_loss: 0.1059 - val_accuracy: 0.9583\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9688 - val_loss: 0.1059 - val_accuracy: 0.9583\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: 0.1057 - val_accuracy: 0.9167\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9792 - val_loss: 0.1080 - val_accuracy: 0.9583\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9896 - val_loss: 0.1040 - val_accuracy: 0.9167\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9688 - val_loss: 0.1036 - val_accuracy: 0.9583\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9688 - val_loss: 0.1051 - val_accuracy: 0.9583\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9896 - val_loss: 0.1033 - val_accuracy: 0.9167\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9688 - val_loss: 0.1015 - val_accuracy: 0.9583\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9688 - val_loss: 0.1018 - val_accuracy: 0.9167\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9896 - val_loss: 0.1023 - val_accuracy: 0.9583\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9688 - val_loss: 0.1002 - val_accuracy: 0.9583\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9688 - val_loss: 0.1009 - val_accuracy: 0.9167\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9688 - val_loss: 0.0999 - val_accuracy: 0.9167\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9896 - val_loss: 0.0997 - val_accuracy: 0.9583\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9688 - val_loss: 0.0978 - val_accuracy: 0.9583\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.0988 - val_accuracy: 0.9167\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9688 - val_loss: 0.0977 - val_accuracy: 0.9167\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 0.0981 - val_accuracy: 0.9583\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9688 - val_loss: 0.0961 - val_accuracy: 0.9583\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9688 - val_loss: 0.1015 - val_accuracy: 0.9583\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9792 - val_loss: 0.0963 - val_accuracy: 0.9583\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9688 - val_loss: 0.0966 - val_accuracy: 0.9167\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9688 - val_loss: 0.0952 - val_accuracy: 0.9583\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9792 - val_loss: 0.0992 - val_accuracy: 0.9583\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9792 - val_loss: 0.0943 - val_accuracy: 0.9583\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.0942 - val_accuracy: 0.9167\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9688 - val_loss: 0.0943 - val_accuracy: 0.9167\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9792 - val_loss: 0.0958 - val_accuracy: 0.9583\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9688 - val_loss: 0.0931 - val_accuracy: 0.9583\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9688 - val_loss: 0.0959 - val_accuracy: 0.9583\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9688 - val_loss: 0.0925 - val_accuracy: 0.9583\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9688 - val_loss: 0.0935 - val_accuracy: 0.9167\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9896 - val_loss: 0.0950 - val_accuracy: 0.9583\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9792 - val_loss: 0.0921 - val_accuracy: 0.9167\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.0912 - val_accuracy: 0.9167\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9688 - val_loss: 0.0924 - val_accuracy: 0.9583\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9688 - val_loss: 0.0911 - val_accuracy: 0.9167\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9688 - val_loss: 0.0916 - val_accuracy: 0.9167\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9688 - val_loss: 0.0909 - val_accuracy: 0.9167\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9896 - val_loss: 0.0911 - val_accuracy: 0.9167\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9896 - val_loss: 0.0907 - val_accuracy: 0.9167\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9688 - val_loss: 0.0898 - val_accuracy: 0.9167\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9688 - val_loss: 0.0892 - val_accuracy: 0.9583\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9792 - val_loss: 0.0900 - val_accuracy: 0.9167\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 0.0889 - val_accuracy: 0.9167\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9792 - val_loss: 0.0930 - val_accuracy: 0.9583\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9688 - val_loss: 0.0891 - val_accuracy: 0.9583\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9688 - val_loss: 0.0885 - val_accuracy: 0.9167\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9896 - val_loss: 0.0890 - val_accuracy: 0.9167\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9896 - val_loss: 0.0885 - val_accuracy: 0.9167\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9688 - val_loss: 0.0880 - val_accuracy: 0.9167\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9688 - val_loss: 0.0879 - val_accuracy: 0.9167\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9896 - val_loss: 0.0899 - val_accuracy: 0.9583\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9688 - val_loss: 0.0874 - val_accuracy: 0.9583\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9688 - val_loss: 0.0876 - val_accuracy: 0.9167\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9792 - val_loss: 0.0867 - val_accuracy: 0.9167\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9688 - val_loss: 0.0866 - val_accuracy: 0.9167\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9896 - val_loss: 0.0879 - val_accuracy: 0.9583\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9896 - val_loss: 0.0895 - val_accuracy: 0.9583\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9688 - val_loss: 0.0870 - val_accuracy: 0.9583\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9688 - val_loss: 0.0878 - val_accuracy: 0.9583\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9688 - val_loss: 0.0865 - val_accuracy: 0.9583\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9792 - val_loss: 0.0881 - val_accuracy: 0.9583\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9896 - val_loss: 0.0860 - val_accuracy: 0.9167\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9792 - val_loss: 0.0870 - val_accuracy: 0.9167\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.0857 - val_accuracy: 0.9167\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9688 - val_loss: 0.0854 - val_accuracy: 0.9167\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9792 - val_loss: 0.0847 - val_accuracy: 0.9167\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9896 - val_loss: 0.0864 - val_accuracy: 0.9167\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9688 - val_loss: 0.0847 - val_accuracy: 0.9583\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9688 - val_loss: 0.0854 - val_accuracy: 0.9583\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.0891 - val_accuracy: 0.9583\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9896 - val_loss: 0.0849 - val_accuracy: 0.9167\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.0843 - val_accuracy: 0.9167\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9688 - val_loss: 0.0847 - val_accuracy: 0.9167\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9896 - val_loss: 0.0867 - val_accuracy: 0.9583\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9688 - val_loss: 0.0860 - val_accuracy: 0.9583\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9792 - val_loss: 0.0851 - val_accuracy: 0.9167\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9896 - val_loss: 0.0854 - val_accuracy: 0.9167\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9896 - val_loss: 0.0836 - val_accuracy: 0.9167\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9688 - val_loss: 0.0839 - val_accuracy: 0.9167\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.0844 - val_accuracy: 0.9167\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9896 - val_loss: 0.0847 - val_accuracy: 0.9167\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9792 - val_loss: 0.0831 - val_accuracy: 0.9167\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9896 - val_loss: 0.0840 - val_accuracy: 0.9167\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9896 - val_loss: 0.0842 - val_accuracy: 0.9167\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9896 - val_loss: 0.0840 - val_accuracy: 0.9167\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9688 - val_loss: 0.0832 - val_accuracy: 0.9583\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9792 - val_loss: 0.0835 - val_accuracy: 0.9167\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9688 - val_loss: 0.0833 - val_accuracy: 0.9167\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9792 - val_loss: 0.0835 - val_accuracy: 0.9167\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9688 - val_loss: 0.0828 - val_accuracy: 0.9583\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9688 - val_loss: 0.0846 - val_accuracy: 0.9167\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9896 - val_loss: 0.0833 - val_accuracy: 0.9167\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9688 - val_loss: 0.0822 - val_accuracy: 0.9167\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9896 - val_loss: 0.0850 - val_accuracy: 0.9583\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9896 - val_loss: 0.0832 - val_accuracy: 0.9167\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9896 - val_loss: 0.0831 - val_accuracy: 0.9583\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9688 - val_loss: 0.0825 - val_accuracy: 0.9167\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9896 - val_loss: 0.0830 - val_accuracy: 0.9167\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9896 - val_loss: 0.0827 - val_accuracy: 0.9167\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9896 - val_loss: 0.0822 - val_accuracy: 0.9167\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0818 - val_accuracy: 0.9167\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.0819 - val_accuracy: 0.9583\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9896 - val_loss: 0.0831 - val_accuracy: 0.9167\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9896 - val_loss: 0.0825 - val_accuracy: 0.9167\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0817 - val_accuracy: 0.9583\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9688 - val_loss: 0.0818 - val_accuracy: 0.9167\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.0820 - val_accuracy: 0.9167\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9896 - val_loss: 0.0828 - val_accuracy: 0.9167\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.0815 - val_accuracy: 0.9583\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.0819 - val_accuracy: 0.9167\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9896 - val_loss: 0.0820 - val_accuracy: 0.9167\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9688 - val_loss: 0.0829 - val_accuracy: 0.9583\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9896 - val_loss: 0.0844 - val_accuracy: 0.9583\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9896 - val_loss: 0.0812 - val_accuracy: 0.9167\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 0.0816 - val_accuracy: 0.9583\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9688 - val_loss: 0.0810 - val_accuracy: 0.9167\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9896 - val_loss: 0.0813 - val_accuracy: 0.9167\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9583\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9688 - val_loss: 0.0821 - val_accuracy: 0.9167\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9688 - val_loss: 0.0815 - val_accuracy: 0.9583\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.9896 - val_loss: 0.0823 - val_accuracy: 0.9167\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.0810 - val_accuracy: 0.9583\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9688 - val_loss: 0.0815 - val_accuracy: 0.9167\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9792 - val_loss: 0.0815 - val_accuracy: 0.9167\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9896 - val_loss: 0.0827 - val_accuracy: 0.9167\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.0810 - val_accuracy: 0.9167\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9792 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9792 - val_loss: 0.0807 - val_accuracy: 0.9167\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9896 - val_loss: 0.0818 - val_accuracy: 0.9167\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.0811 - val_accuracy: 0.9167\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9792 - val_loss: 0.0808 - val_accuracy: 0.9167\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9792 - val_loss: 0.0809 - val_accuracy: 0.9167\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9896 - val_loss: 0.0820 - val_accuracy: 0.9167\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9896 - val_loss: 0.0832 - val_accuracy: 0.9167\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9792 - val_loss: 0.0846 - val_accuracy: 0.9583\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9792 - val_loss: 0.0816 - val_accuracy: 0.9583\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9896 - val_loss: 0.0836 - val_accuracy: 0.9167\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9896 - val_loss: 0.0808 - val_accuracy: 0.9167\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9896 - val_loss: 0.0803 - val_accuracy: 0.9167\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9688 - val_loss: 0.0803 - val_accuracy: 0.9583\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9792 - val_loss: 0.0830 - val_accuracy: 0.9167\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9792 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9896 - val_loss: 0.0815 - val_accuracy: 0.9167\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9896 - val_loss: 0.0816 - val_accuracy: 0.9167\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9896 - val_loss: 0.0815 - val_accuracy: 0.9583\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9792 - val_loss: 0.0810 - val_accuracy: 0.9167\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9896 - val_loss: 0.0810 - val_accuracy: 0.9167\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9688 - val_loss: 0.0814 - val_accuracy: 0.9583\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9792 - val_loss: 0.0849 - val_accuracy: 0.9583\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9896 - val_loss: 0.0819 - val_accuracy: 0.9167\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9896 - val_loss: 0.0818 - val_accuracy: 0.9167\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9792 - val_loss: 0.0833 - val_accuracy: 0.9583\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9792 - val_loss: 0.0821 - val_accuracy: 0.9167\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9896 - val_loss: 0.0815 - val_accuracy: 0.9167\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9896 - val_loss: 0.0814 - val_accuracy: 0.9167\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9896 - val_loss: 0.0819 - val_accuracy: 0.9167\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9896 - val_loss: 0.0816 - val_accuracy: 0.9167\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9688 - val_loss: 0.0835 - val_accuracy: 0.9583\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9688 - val_loss: 0.0817 - val_accuracy: 0.9167\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9896 - val_loss: 0.0834 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "m=model.fit(X_train,y_train, epochs=300, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RpFWHtSnAqi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0f0158130>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(m.history['loss'])\n",
    "plt.plot(m.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe0f009c580>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m.history['accuracy'])\n",
    "plt.plot(m.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1205 - accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9-Qryk9nAsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1204957515001297, 0.9666666388511658]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 0, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)  # category output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 0, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test), axis=-1)  # predict classes update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yP5d3Y9nAvU"
   },
   "outputs": [],
   "source": [
    "data1=data.iloc[149:150,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cA2hbzH0nAwq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "149           5.9          3.0           5.1          1.8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "149           5.9          3.0           5.1          1.8        2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[149:150,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test1=data.iloc[149:150,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(data1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.084595e-06, 9.869935e-02, 9.012996e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data1)     #  probabilty output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bnuR0FBnA27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "a=model.predict_classes(data1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(data1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep_Learning_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
